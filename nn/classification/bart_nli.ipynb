{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import transformers\n",
    "from transformers import pipeline\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'sequence': 'one day I will see the world',\n",
       "  'labels': ['travel', 'exploration', 'dancing', 'cooking'],\n",
       "  'scores': [0.7957560420036316,\n",
       "   0.1993318647146225,\n",
       "   0.0026212281081825495,\n",
       "   0.0022907459642738104]},\n",
       " {'sequence': 'best steak in america',\n",
       "  'labels': ['cooking', 'exploration', 'travel', 'dancing'],\n",
       "  'scores': [0.7510271668434143,\n",
       "   0.1638369858264923,\n",
       "   0.06331372261047363,\n",
       "   0.02182212844491005]}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences_to_classify = [\"one day I will see the world\", \"best steak in america\"]\n",
    "candidate_labels = ['travel', 'cooking', 'dancing', 'exploration']\n",
    "classifier(sequences_to_classify, candidate_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformers.pipelines.zero_shot_classification.ZeroShotClassificationPipeline"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = classifier(sequences_to_classify, candidate_labels, multi_label=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'sequence': 'one day I will see the world',\n",
       "  'labels': ['travel', 'exploration', 'dancing', 'cooking'],\n",
       "  'scores': [0.994511067867279,\n",
       "   0.9383884072303772,\n",
       "   0.005706187337636948,\n",
       "   0.001819287077523768]},\n",
       " {'sequence': 'best steak in america',\n",
       "  'labels': ['cooking', 'exploration', 'travel', 'dancing'],\n",
       "  'scores': [0.5870057344436646,\n",
       "   0.007772187702357769,\n",
       "   0.0012448065681383014,\n",
       "   9.23419720493257e-05]}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>travel</th>\n",
       "      <th>cooking</th>\n",
       "      <th>dancing</th>\n",
       "      <th>exploration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>one day I will see the world</th>\n",
       "      <td>0.994511</td>\n",
       "      <td>0.001819</td>\n",
       "      <td>0.005706</td>\n",
       "      <td>0.938388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>best steak in america</th>\n",
       "      <td>0.001245</td>\n",
       "      <td>0.587006</td>\n",
       "      <td>0.000092</td>\n",
       "      <td>0.007772</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                travel   cooking   dancing  exploration\n",
       "one day I will see the world  0.994511  0.001819  0.005706     0.938388\n",
       "best steak in america         0.001245  0.587006  0.000092     0.007772"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(0, index=sequences_to_classify, columns=candidate_labels)\n",
    "\n",
    "nlabels = len(candidate_labels)\n",
    "for r in results:\n",
    "    for i in range(nlabels):\n",
    "        df.loc[r['sequence'], r['labels'][i]] = r['scores'][i]\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manual step by step\n",
    "nli_model = AutoModelForSequenceClassification.from_pretrained('facebook/bart-large-mnli')\n",
    "tokenizer = AutoTokenizer.from_pretrained('facebook/bart-large-mnli')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\arunch\\Anaconda3\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2356: FutureWarning: The `truncation_strategy` argument is deprecated and will be removed in a future version, use `truncation=True` to truncate examples to a max length. You can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to truncate to the maximal input size of the model (e.g. 512 for Bert).  If you have pairs of inputs, you can give a specific truncation strategy selected among `truncation='only_first'` (will only truncate the first sentence in the pairs) `truncation='only_second'` (will only truncate the second sentence in the pairs) or `truncation='longest_first'` (will iteratively remove tokens from the longest sentence in the pairs).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[   0, 1264,  183,   38,   40,  192,    5,  232,    2,    2,  713, 1246,\n",
       "           16, 1504,    4,    2],\n",
       "        [   0, 1264,  183,   38,   40,  192,    5,  232,    2,    2,  713, 1246,\n",
       "           16, 6836,    4,    2],\n",
       "        [   0, 1264,  183,   38,   40,  192,    5,  232,    2,    2,  713, 1246,\n",
       "           16, 7950,    4,    2],\n",
       "        [   0, 1264,  183,   38,   40,  192,    5,  232,    2,    2,  713, 1246,\n",
       "           16, 6942,    4,    2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hypotheses = [f'This example is {l}.' for l in candidate_labels]\n",
    "premises = [sequence] * len(hypotheses)\n",
    "\n",
    "x = tokenizer(premises, hypotheses, return_tensors='pt',\n",
    "                     truncation_strategy='only_first')\n",
    "\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-3.0856,  1.0612,  2.1139],\n",
       "        [ 2.5710,  1.2230, -3.7365],\n",
       "        [ 1.5588,  1.7296, -3.6017],\n",
       "        [-1.9937,  1.3917,  0.7296]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = nli_model(**x)\n",
    "logits = y.logits\n",
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0055, 0.9945],\n",
       "        [0.9982, 0.0018],\n",
       "        [0.9943, 0.0057],\n",
       "        [0.0616, 0.9384]], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we throw away \"neutral\" (dim 1) and take the probability of\n",
    "# \"entailment\" (2) as the probability of the label being true \n",
    "e_c_logits = logits[:, [0, 2]]\n",
    "e_c_logits.softmax(dim=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d6a2ed50b9e4eaa101095046af0807d99d7745b36820485d55a169bc42680a05"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
